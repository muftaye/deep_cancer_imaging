{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muftaye/deep_cancer_imaging/blob/master/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf3d4UQMNUTP",
        "colab_type": "text"
      },
      "source": [
        "## About\n",
        "\n",
        "This starter code shows how to read slides and tumor masks from the [CAMELYON16](https://camelyon17.grand-challenge.org/Data/) dataset. It will install [OpenSlide](https://openslide.org/) in Colab (the only non-Python dependency). Note that OpenSlide also includes a [DeepZoom viewer](https://github.com/openslide/openslide-python/tree/master/examples/deepzoom), shown in class. To use that, you'll need to install and run OpenSlide locally on your computer.\n",
        "\n",
        "### Training data\n",
        "\n",
        "The original slides and annotations are in an unusual format. I converted a bunch of them for you, so you can read them with OpenSlide as shown in this notebook. This [folder](https://drive.google.com/drive/folders/1rwWL8zU9v0M27BtQKI52bF6bVLW82RL5?usp=sharing) contains all the slides and tumor masks I converted (and these should be *plenty* for your project). If you'd like more beyond this, you'll need to use ASAP as described on the competition website to convert it into an appropriate format. \n",
        "\n",
        "Note that even with the starter code, it will take some effort to understand how to work with this data (the various zoom levels, and the coordinate system). Happy to help in OH if you're stuck.\n",
        "\n",
        "### Reminder\n",
        "\n",
        "The goal for your project is to build a thoughtful, end-to-end prototype - not to match the accuracy from the [paper](https://arxiv.org/abs/1703.02442), or use all the available data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFDFRpKaNads",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the OpenSlide C library and Python bindings\n",
        "!apt-get install openslide-tools\n",
        "!pip install openslide-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AWOh8BCNfhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from openslide import open_slide, __library_version__ as openslide_version\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK6FGwluqtra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download an example slide and tumor mask\n",
        "\n",
        "# Note: the remainder of the training data are in the Google Drive folder linked above.\n",
        "# You will need to host them on your own, either in Google Drive, or by using\n",
        "# the cloud provider of your choice.\n",
        "\n",
        "slide_path = 'tumor_091.tif' # only this file is available\n",
        "tumor_mask_path = 'tumor_091_mask.tif' # only this file is available\n",
        "\n",
        "slide_url = 'https://storage.googleapis.com/applied-dl/%s' % slide_path\n",
        "mask_url = 'https://storage.googleapis.com/applied-dl/%s' % tumor_mask_path\n",
        "\n",
        "# Download the whole slide image\n",
        "if not os.path.exists(slide_path):\n",
        "  !curl -O $slide_url\n",
        "\n",
        "# Download the tumor mask\n",
        "if not os.path.exists(tumor_mask_path):\n",
        "  !curl -O $mask_url"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59jglJ_lqx8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slide = open_slide(slide_path)\n",
        "print (\"Read WSI from %s with width: %d, height: %d\" % (slide_path, \n",
        "                                                        slide.level_dimensions[0][0], \n",
        "                                                        slide.level_dimensions[0][1]))\n",
        "\n",
        "tumor_mask = open_slide(tumor_mask_path)\n",
        "print (\"Read tumor mask from %s\" % (tumor_mask_path))\n",
        "\n",
        "print(\"Slide includes %d levels\", len(slide.level_dimensions))\n",
        "for i in range(len(slide.level_dimensions)):\n",
        "    print(\"Level %d, dimensions: %s downsample factor %d\" % (i, \n",
        "                                                             slide.level_dimensions[i], \n",
        "                                                             slide.level_downsamples[i]))\n",
        "    assert tumor_mask.level_dimensions[i][0] == slide.level_dimensions[i][0]\n",
        "    assert tumor_mask.level_dimensions[i][1] == slide.level_dimensions[i][1]\n",
        "\n",
        "# Verify downsampling works as expected\n",
        "width, height = slide.level_dimensions[7]\n",
        "assert width * slide.level_downsamples[7] == slide.level_dimensions[0][0]\n",
        "assert height * slide.level_downsamples[7] == slide.level_dimensions[0][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68KfVQs-v9tJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See https://openslide.org/api/python/#openslide.OpenSlide.read_region\n",
        "# Note: x,y coords are with respect to level 0.\n",
        "# There is an example below of working with coordinates\n",
        "# with respect to a higher zoom level.\n",
        "\n",
        "# Read a region from the slide\n",
        "# Return a numpy RBG array\n",
        "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
        "    im = slide.read_region((x,y), level, (width, height))\n",
        "    im = im.convert('RGB') # drop the alpha channel\n",
        "    if as_float:\n",
        "        im = np.asarray(im, dtype=np.float32)\n",
        "    else:\n",
        "        im = np.asarray(im)\n",
        "    assert im.shape == (height, width, 3)\n",
        "    return im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wcBX1LAwAVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example: read the entire slide at level 5\n",
        "\n",
        "# Higher zoom levels may not fit into memory.\n",
        "# You can use the below function to extract regions from higher zoom levels \n",
        "# without having to read the entire image into ram.\n",
        "\n",
        "# Use the sliding window approach discussed in class to collect training\n",
        "# data for your classifier. E.g., slide a window across the slide (for\n",
        "# starters, use a zoomed out view, so you're not working with giant images).\n",
        "# Save each window to disk as an image. To find the label for that image, \n",
        "# check to the tissue mask to see if the same region contains cancerous cells.\n",
        "\n",
        "# Important: this is tricky to get right. Carefully debug your pipeline before\n",
        "# training your model. Start with just a single image, and a relatively \n",
        "# low zoom level.\n",
        "\n",
        "slide_image = read_slide(slide, \n",
        "                         x=0, \n",
        "                         y=0, \n",
        "                         level=5, \n",
        "                         width=slide.level_dimensions[5][0], \n",
        "                         height=slide.level_dimensions[5][1])\n",
        "\n",
        "plt.figure(figsize=(10,10), dpi=100)\n",
        "plt.imshow(slide_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86cT2_ZcwDjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example: read the entire mask at the same zoom level\n",
        "mask_image = read_slide(tumor_mask, \n",
        "                        x=0, \n",
        "                        y=0, \n",
        "                        level=5, \n",
        "                        width=slide.level_dimensions[5][0], \n",
        "                        height=slide.level_dimensions[5][1])\n",
        "\n",
        "# Note: the program provided by the dataset authors generates a mask with R,G,B channels.\n",
        "# The mask info we need is in the first channel only.\n",
        "# If you skip this step, the mask will be displayed as all black.\n",
        "mask_image = mask_image[:,:,0]\n",
        "\n",
        "plt.figure(figsize=(10,10), dpi=100)\n",
        "plt.imshow(mask_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywWaBpzowGHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Overlay them. The idea is that the mask shows the region of the slide that\n",
        "# contain cancerous cells.\n",
        "plt.figure(figsize=(10,10), dpi=100)\n",
        "plt.imshow(slide_image)\n",
        "plt.imshow(mask_image, cmap='jet', alpha=0.5) # Red regions contains cancer."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14W75yz8wOcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example: extract a region from the L7 downsampled image\n",
        "# Notice we're multiplying the x,y coordinates by the downsample factor.\n",
        "# This math can be tricky to get right, debug carefully.\n",
        "# Here, we're \"aiming\" for the top right blob in the image above.\n",
        "region = read_slide(tumor_mask, x=350 * 128, y=120 * 128, level=7, width=50, height=50)[:,:,0]\n",
        "plt.imshow(region)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dSRhrAEwbpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As mentioned in class, we can improve efficiency by ignoring non-tissue areas \n",
        "# of the slide. We'll find these by looking for all gray regions.\n",
        "def find_tissue_pixels(image, intensity=0.8):\n",
        "    im_gray = rgb2gray(image)\n",
        "    assert im_gray.shape == (image.shape[0], image.shape[1])\n",
        "    indices = np.where(im_gray <= intensity)\n",
        "    return zip(indices[0], indices[1])\n",
        "\n",
        "tissue_pixels = find_tissue_pixels(slide_image)\n",
        "percent_tissue = len(tissue_pixels) / float(slide_image.shape[0] * slide_image.shape[0]) * 100\n",
        "print (\"%d tissue_pixels pixels (%.1f percent of the image)\" % (len(tissue_pixels), percent_tissue)) \n",
        "\n",
        "def apply_mask(im, mask, color=(255,0,0)):\n",
        "    masked = np.copy(im)\n",
        "    for x,y in mask: masked[x][y] = color\n",
        "    return masked\n",
        "\n",
        "tissue_regions = apply_mask(slide_image, tissue_pixels)\n",
        "plt.imshow(tissue_regions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV3a4MNPwuVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}